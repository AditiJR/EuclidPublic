<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Euclid AI Helper</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            overflow: hidden;
        }
        .animate-spin-slow {
            animation: spin 2s linear infinite;
        }
        @keyframes spin {
            from { transform: rotate(0deg); }
            to { transform: rotate(360deg); }
        }
        pre {
            white-space: pre-wrap;
            word-wrap: break-word;
            background-color: rgba(255, 255, 255, 0.05);
            padding: 8px;
            border-radius: 4px;
            margin-top: 8px;
            font-family: monospace;
        }
    </style>
</head>
<body class="bg-black text-white h-screen flex flex-col">

    <div class="relative flex-grow w-full h-full">
        <video id="video" class="absolute inset-0 w-full h-full object-cover" autoplay playsinline></video>
        <div id="video-off-overlay" class="absolute inset-0 w-full h-full bg-black hidden items-center justify-center">
            <p class="text-xl text-gray-400">Video is Off</p>
        </div>

        <header class="absolute top-0 left-0 right-0 p-4 bg-gradient-to-b from-black/50 to-transparent">
            <h1 class="text-2xl font-bold text-center">Euclid</h1>
            <p id="instruction" class="text-center text-gray-300 mt-1">Say "Hey Euclid, can you help me?"</p>
        </header>

        <div id="response-container" class="absolute top-4 right-4 w-80 max-w-[90vw] bg-black/50 backdrop-blur-md rounded-lg p-4 border border-white/10 shadow-lg transform translate-x-[150%] transition-transform duration-500 ease-in-out">
            <div id="response-content" class="text-sm">
            </div>
        </div>

        <div id="flash" class="absolute inset-0 bg-white opacity-0 pointer-events-none"></div>
    </div>

    <footer class="bg-black/50 p-3 flex justify-center items-center gap-6 border-t border-white/10">
    <button id="video-toggle" title="Toggle Video" class="text-white hover:text-blue-400 transition-colors">
        <svg id="video-on-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15.6 11.6L22 7v10l-6.4-4.6Z"/><path d="M2 5h11a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V7a2 2 0 0 1 2-2Z"/></svg>
        <svg id="video-off-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="hidden"><path d="M15.6 11.6L22 7v10l-6.4-4.6Z"/><path d="m2 2 20 20"/><path d="M12 18H3a1 1 0 0 1-1-1V7a1 1 0 0 1 1-1h.5"/><path d="M15 15.5V13a2 2 0 0 0-2-2H7.5"/></svg>
    </button>
    <div id="status" class="text-sm font-medium text-gray-300 flex items-center gap-2">
        <div id="mic-active-dot" class="w-2 h-2 bg-green-500 rounded-full"></div>
        <span id="status-text">Listening...</span>
    </div>
    <button id="mute-toggle" title="Toggle Mic" class="text-white hover:text-blue-400 transition-colors">
        <svg id="mic-on-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><line x1="12" x2="12" y1="19" y2="22"/></svg>
        <svg id="mic-off-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="hidden"><path d="m12 2-1.1 1.1a5 5 0 0 0-4.1 7.1L2 15"/><path d="M15.1 3.9a5 5 0 0 1-1.1 7.1L12 13"/><path d="M22 10v2a7 7 0 0 1-12.2 5.9"/><line x1="12" x2="12" y1="19" y2="22"/><line x1="2" x2="22" y1="2" y2="22"/></svg>
    </button>
</footer>
    <script>
        // ... (all other variables and functions like setupRecognition, startCamera, playAudioResponse, etc. are unchanged) ...
        const video = document.getElementById('video');
        const flash = document.getElementById('flash');
        const responseContainer = document.getElementById('response-container');
        const responseContent = document.getElementById('response-content');
        const instruction = document.getElementById('instruction');
        const statusText = document.getElementById('status-text');
        const micActiveDot = document.getElementById('mic-active-dot');

        const muteToggle = document.getElementById('mute-toggle');
        const micOnIcon = document.getElementById('mic-on-icon');
        const micOffIcon = document.getElementById('mic-off-icon');
        const videoToggle = document.getElementById('video-toggle');
        const videoOnIcon = document.getElementById('video-on-icon');
        const videoOffIcon = document.getElementById('video-off-icon');
        const videoOffOverlay = document.getElementById('video-off-overlay');

        let isMuted = false;
        let isVideoOff = false;
        let stream;
        let responseTimer;
        let audio;

        let sessionSteps = [];
        let currentStepIndex = -1; // No longer used for iteration, but useful for state
        let isSessionActive = false;

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;
        
        function setupRecognition() {
            if (!SpeechRecognition) {
                instruction.textContent = 'Speech recognition not supported in this browser.';
                return null;
            }
            const rec = new SpeechRecognition();
            rec.continuous = true;
            rec.interimResults = false;
            rec.lang = 'en-US';
            
            rec.onresult = (event) => {
                const transcript = event.results[event.results.length - 1][0].transcript.trim().toLowerCase();
                console.log('Heard:', transcript);

                const triggerPhrases = [
                    'hey euclid can you help me', 'please help me', 'help',
                    'what do i do next', "what's next", 'whats next', 'go on',
                    'keep going', 'okay next'
                ];

                if (triggerPhrases.some(phrase => transcript.includes(phrase))) {
                    handleTrigger();
                }
            };
            
            rec.onerror = (event) => {
                if (event.error !== 'no-speech' && event.error !== 'aborted') {
                    console.error('Speech recognition error:', event.error);
                }
            };

            rec.onend = () => {
                if (!isMuted && !isVideoOff) {
                    try { recognition.start(); } catch (e) { /* ignore */ }
                }
            };
            return rec;
        }

        recognition = setupRecognition();

        async function startCamera() {
            try {
                if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                    stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                    video.srcObject = stream;
                    video.style.display = 'block';
                    videoOffOverlay.classList.add('hidden');
                    isVideoOff = false;
                    updateVideoIcons();
                    startRecognition();
                }
            } catch (err) {
                console.error("Error accessing camera:", err);
                instruction.textContent = 'Could not access the camera.';
            }
        }

        function stopCamera() {
            if (stream) stream.getTracks().forEach(track => track.stop());
            video.srcObject = null;
            video.style.display = 'none';
            videoOffOverlay.classList.remove('hidden');
            isVideoOff = true;
            updateVideoIcons();
            stopRecognition();
        }

        function startRecognition() {
            if (recognition && !isMuted && !isVideoOff) {
                try {
                    recognition.start();
                    updateStatus(true);
                } catch(e) { console.warn("Recognition already started."); }
            }
        }

        function stopRecognition() {
            if (recognition) {
                recognition.stop();
                updateStatus(false);
            }
        }
        
        async function playAudioResponse(text, onStartCallback) {
            // --- Fill in your credentials here ---
            const XI_API_KEY = "";
            const VOICE_ID = "jsCqWAovK2LkecY7zXl4"; // Freya

            // API endpoint URL
            const url = `https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}`;

            // Request options
            const options = {
                method: 'POST',
                headers: {
                    'Accept': 'audio/mpeg',
                    'Content-Type': 'application/json',
                    'xi-api-key': XI_API_KEY
                },
                body: JSON.stringify({
                    text: text,
                    model_id: "eleven_monolingual_v1", // A standard, high-quality model
                    voice_settings: {
                        stability: 0.5,
                        similarity_boost: 0.5
                    }
                })
            };

            // --- The API Call ---
            return new Promise(async (resolve, reject) => {
                if (audio && !audio.paused) {
                    audio.pause();
                }

                console.log("ðŸ”Š Calling real ElevenLabs API...");
                if (onStartCallback) onStartCallback();

                try {
                    const response = await fetch(url, options);

                    if (!response.ok) {
                        // If the API returns an error, log it and reject
                        const errorData = await response.json();
                        console.error("ElevenLabs API Error:", errorData);
                        throw new Error(`API Error: ${response.status}`);
                    }

                    // The API returns the audio file directly as a blob
                    const audioBlob = await response.blob();
                    const audioUrl = URL.createObjectURL(audioBlob);
                    audio = new Audio(audioUrl);

                    audio.onended = () => resolve();
                    audio.onerror = (e) => reject(e);
                    
                    audio.play();

                } catch (error) {
                    console.error("Failed to play audio from ElevenLabs:", error);
                    reject(error);
                }
            });
        }
        
        function captureFrameAsBlob() {
            return new Promise((resolve) => {
                const canvas = document.createElement('canvas');
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                const context = canvas.getContext('2d');
                context.drawImage(video, 0, 0, canvas.width, canvas.height);
                canvas.toBlob(resolve, 'image/png');
            });
        }
        
        // --- MODIFIED: Main function to handle backend API calls ---
        async function handleTrigger() {
            console.log('Trigger word detected!');
            
            if (responseTimer) clearTimeout(responseTimer);

            flash.style.opacity = '0.7';
            setTimeout(() => { flash.style.opacity = '0'; }, 150);
            
            responseContainer.classList.remove('translate-x-[150%]');
            responseContent.innerHTML = `
                <div class="flex items-center space-x-2">
                    <svg class="animate-spin-slow h-5 w-5 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                        <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                        <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                    </svg>
                    <span>Euclid is thinking...</span>
                </div>`;

            try {
                const frameBlob = await captureFrameAsBlob();
                if (!frameBlob) {
                    throw new Error("Could not capture video frame.");
                }

                const formData = new FormData();
                formData.append('image', frameBlob, 'capture.png');

                let stepForUI;

                if (!isSessionActive) {
                    // --- First request: Start a new session, get all steps ---
                    console.log("Starting new session, calling /steps");
                    const response = await fetch('http://localhost:8001/steps', {
                        method: 'POST',
                        body: formData
                    });

                    if (!response.ok) throw new Error(`Steps API Error: ${response.status}`);
                    
                    const data = await response.json();
                    if (!data.steps || data.steps.length === 0) throw new Error("No steps received from API.");
                    
                    sessionSteps = data.steps; // Store the context
                    isSessionActive = true;
                    currentStepIndex = 0;
                    
                    const firstStep = sessionSteps[0];
                    stepForUI = {
                        displayText: `<strong>Step ${firstStep.step_id + 1}: ${firstStep.nudge}</strong><pre>${firstStep.answer}</pre>`,
                        speechText: firstStep.nudge
                    };

                } else {
                    // --- Subsequent request: Call checkprogress to get the next step ---
                    console.log("Session active, calling /checkprogress");
                    const response = await fetch('http://localhost:8001/checkprogress', {
                        method: 'POST',
                        body: formData
                    });

                    if (!response.ok) throw new Error(`CheckProgress API Error: ${response.status}`);
                    
                    const progressData = await response.json();
                    
                    // The server now tells us what to say and display
                    stepForUI = {
                        displayText: progressData.response_text,
                        speechText: progressData.response_text
                    };

                    // Check if the server signaled that the problem is finished
                    if (progressData.response_text.includes("Problem Solved")) {
                        console.log("Problem finished. Resetting session.");
                        isSessionActive = false;
                        currentStepIndex = -1;
                        sessionSteps = [];
                    }
                }

                // --- Update UI with the received step ---
                const showTalkingStatus = () => {
                    responseContent.innerHTML = `
                        <div class="flex items-center space-x-2">
                            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="9" y="9" width="6" height="6" rx="1"/><path d="M12 15v3"/><path d="M12 9V6"/><path d="M15 12h3"/><path d="M9 12H6"/></svg>
                            <span>Euclid is talking...</span>
                        </div>`;
                };
                
                await playAudioResponse(stepForUI.speechText, showTalkingStatus);
                responseContent.innerHTML = `<p>${stepForUI.displayText}</p>`;
        
                responseTimer = setTimeout(() => {
                    responseContainer.classList.add('translate-x-[150%]');
                }, 30000);

            } catch (error) {
                console.error("Failed to get response from backend:", error);
                responseContent.innerHTML = `<p class="text-red-400">Sorry, there was an error communicating with Euclid. Please try again.</p>`;
                // Reset session on error
                isSessionActive = false;
                currentStepIndex = -1;
                sessionSteps = [];
            }
        }
        
        function updateStatus(isListening) {
            if(isListening && !isMuted && !isVideoOff) {
                statusText.textContent = "Listening...";
                micActiveDot.className = 'w-2 h-2 bg-green-500 rounded-full';
            } else if (isVideoOff) {
                statusText.textContent = "Video Off";
                micActiveDot.className = 'w-2 h-2 bg-red-500 rounded-full';
            } else if (isMuted) {
                statusText.textContent = "Muted";
                micActiveDot.className = 'w-2 h-2 bg-red-500 rounded-full';
            }
        }

        function updateMuteIcons() {
            micOnIcon.classList.toggle('hidden', isMuted);
            micOffIcon.classList.toggle('hidden', !isMuted);
        }

        function updateVideoIcons() {
            videoOnIcon.classList.toggle('hidden', isVideoOff);
            videoOffIcon.classList.toggle('hidden', !isVideoOff);
        }

        muteToggle.addEventListener('click', () => {
            isMuted = !isMuted;
            updateMuteIcons();
            if (isMuted) stopRecognition();
            else startRecognition();
        });

        videoToggle.addEventListener('click', () => {
            if (isVideoOff) startCamera();
            else stopCamera();
        });

        responseContainer.addEventListener('click', () => {
            if (responseTimer) clearTimeout(responseTimer);
            responseContainer.classList.add('translate-x-[150%]');
        });

        startCamera();
    </script>
</body>
</html>